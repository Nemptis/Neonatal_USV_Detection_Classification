{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece00f25-e08c-47e6-8a83-122a38369d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13e3b94-65b2-4107-bbd5-42aa9b479018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from usv_detection import construct_csv_from_wav_file\n",
    "from mouse_dataset import mouse_dataset\n",
    "from mel_dataset import MouseAudioDataset_RegularSpectrogram\n",
    "from classification_net_cnn import classification_net_cnn_image_lightning, classification_net_cnn_image_lightning_EfficentNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03b2fe5-6f68-4970-8064-1bb2429b5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_file_list\n",
    "from config import DEVICE\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625feef9-bd40-45af-85cd-8fdba8c21b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41301138-055f-409e-86db-75bcacb16b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# those are the mean and standard deviation values of the normal spectorgram and DB scaled spectrogram\n",
    "# from the labeled dataset (manual detection and manual classification)\n",
    "MEAN_SPECTROGRAM = 217957840.0\n",
    "STD_SPECTROGRAM = 29768316928.0\n",
    "MEAN_DB_SPECTROGRAM = 58.01118087768555\n",
    "STD_DB_SPECTROGRAM = 6.819430828094482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4963a70-04aa-4410-a38d-8533f6867950",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\" #\"/Users/johannmaass/Desktop/Doktor/ZeTeM/Rudolf_net_2/Data\"\n",
    "MODEL_PATH_CUSTOM_CNN = \"models/custom_cnn/epoch=139-step=12880.ckpt\"#\"/Users/johannmaass/Desktop/Doktor/ZeTeM/Rudolf_net_2/Checkpoints/CustomCNN/version_0/checkpoints/epoch=139-step=12880.ckpt\"\n",
    "MODEL_PATH_EFFICENTNETB5 = \"models/efficientnetb5/epoch=19-step=1840.ckpt\" #\"/Users/johannmaass/Desktop/Doktor/ZeTeM/Rudolf_net_2/Checkpoints/efficentnetb5/version_0/checkpoints/epoch=19-step=1840.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4535356-8db0-4b8f-9416-a54f28fc177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.6.0 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint f:\\git\\Neonatal_USV_Detection_Classification\\models\\custom_cnn\\epoch=139-step=12880.ckpt`\n",
      "f:\\git\\Neonatal_USV_Detection_Classification\\usv_detection.py:29: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  samplerate, data = wavfile.read(wav_file)\n",
      "f:\\git\\Neonatal_USV_Detection_Classification\\mouse_dataset.py:157: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sampling_rate, signal = wavfile.read(wav_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected 157 calls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]f:\\git\\Neonatal_USV_Detection_Classification\\classification_net_cnn.py:1006: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n",
      "100%|██████████| 10/10 [00:00<00:00, 24.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n# efficentnet b5\\nrun_evaluation(\\n    data_folder_dir=DATA_DIR,\\n    model_path=MODEL_PATH_EFFICENTNETB5,\\n    model_class=classification_net_cnn_image_lightning_EfficentNetB5,\\n    confidence_threshold=0.4,\\n    normalize_smooth_spec_individually=True,\\n    plot_images=False,\\n)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dataset(folder_dir, normalize_smooth_spec_individually=False):\n",
    "    \"\"\"creates the dataset from a folder that contains the .WAV and detections.csv files\n",
    "\n",
    "    normalize_smooth_spec_individually: set to False for the custom cnn,\n",
    "                set to True for the EfficentNetB5\n",
    "    \"\"\"\n",
    "\n",
    "    # use mouse_dataset to extract the whole signal, the start end times and duration of\n",
    "    # the individual calls\n",
    "    auto_manu_ds = mouse_dataset.from_folder(\n",
    "        folder_dir,\n",
    "        name=\"auto-manu-set\",\n",
    "        categories=[1, 2, 3, 4, 5],\n",
    "        category_map={\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5},\n",
    "        pad_start_ms=60,\n",
    "        pad_end_ms=60,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # build a new dataset from the data of the mouse_dataset\n",
    "    dataset = MouseAudioDataset_RegularSpectrogram(\n",
    "        auto_manu_ds.data,\n",
    "        mean_spectogram=MEAN_SPECTROGRAM,\n",
    "        std_spectogram=STD_SPECTROGRAM,\n",
    "        mean_scaled_spectogram=MEAN_DB_SPECTROGRAM,\n",
    "        std_scaled_spectogram=STD_DB_SPECTROGRAM,\n",
    "        final_crop_size_no_aug=170,\n",
    "        normalize_smooth_spec_individually=normalize_smooth_spec_individually,\n",
    "        resize_size=None,\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def dataset_from_wav_file(wav_file, normalize_smooth_spec_individually=False):\n",
    "    csv_file = construct_csv_from_wav_file(wav_file)\n",
    "\n",
    "    auto_mouse_ds = mouse_dataset.from_wav_csv_files(\n",
    "        wav_files=[wav_file],\n",
    "        csv_files=[csv_file],\n",
    "        name=\"auto-manu-set\",\n",
    "        categories=[1, 2, 3, 4, 5],\n",
    "        category_map={\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5},\n",
    "        pad_start_ms=60,\n",
    "        pad_end_ms=60,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    dataset = MouseAudioDataset_RegularSpectrogram(\n",
    "        auto_mouse_ds.data,\n",
    "        mean_spectogram=MEAN_SPECTROGRAM,\n",
    "        std_spectogram=STD_SPECTROGRAM,\n",
    "        mean_scaled_spectogram=MEAN_DB_SPECTROGRAM,\n",
    "        std_scaled_spectogram=STD_DB_SPECTROGRAM,\n",
    "        final_crop_size_no_aug=170,\n",
    "        normalize_smooth_spec_individually=normalize_smooth_spec_individually,\n",
    "        resize_size=None,\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model_path, model_class):\n",
    "    model = model_class.load_from_checkpoint(model_path).eval().to(DEVICE)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def example_run_model(\n",
    "    data_folder_dir, model_path, model_class, normalize_smooth_spec_individually=False\n",
    "):\n",
    "    model = load_model(model_path, model_class)\n",
    "    dataset = create_dataset(\n",
    "        data_folder_dir,\n",
    "        normalize_smooth_spec_individually=normalize_smooth_spec_individually,\n",
    "    )\n",
    "\n",
    "    # set the batch_size so that it still fits in VRAM / RAM (depending on what DEVICE is used)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # just a dummy loop running the model over the data\n",
    "    for spectrogram, target in tqdm(dataloader):\n",
    "        # no training, so no need to track gradients here\n",
    "        with torch.no_grad():\n",
    "            pred = model(spectrogram.to(DEVICE))\n",
    "            predicted_categories = torch.argmax(pred, dim=1).cpu()\n",
    "            predictions.append(predicted_categories)\n",
    "\n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "    for category_class in range(5):\n",
    "        print(\n",
    "            \"category: {}, num calls: {}\".format(\n",
    "                category_class + 1, torch.sum(predictions == category_class)\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def run_evaluation(data_folder_dir, model_path, model_class, normalize_smooth_spec_individually=False, confidence_threshold=0.0,\n",
    "                   plot_images=False\n",
    "):\n",
    "    model = load_model(model_path, model_class)\n",
    "    wav_files = get_file_list(data_folder_dir, ext=\".WAV\")\n",
    "\n",
    "    num_calls_per_category_csv = [\"Number of Calls per Category\"]\n",
    "    categories_csv = [\"Call Category\"]\n",
    "    wav_files_csv = [\"File Name\"]\n",
    "\n",
    "    for wav_file in wav_files:\n",
    "        spectrograms_db_scale_per_category = [[] for i in range(6)]\n",
    "        predictions = []\n",
    "        dataset = dataset_from_wav_file(\n",
    "            wav_file,\n",
    "            normalize_smooth_spec_individually=normalize_smooth_spec_individually,\n",
    "        )\n",
    "\n",
    "        dataloader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "        for spectrogram, _ in tqdm(dataloader):\n",
    "            with torch.no_grad():\n",
    "                pred = model(spectrogram.to(DEVICE))\n",
    "                confidences, _ = torch.max(pred, dim=1)\n",
    "                predicted_categories = torch.argmax(pred, dim=1)\n",
    "                for idx, confidence in enumerate(confidences):\n",
    "                    if confidence > confidence_threshold:\n",
    "                        predictions.append(predicted_categories[idx].unsqueeze(dim=0).cpu())\n",
    "                        spectrograms_db_scale_per_category[predicted_categories[idx]+1].append(spectrogram[idx, 1])\n",
    "                    else:\n",
    "                        # set to -1 for usv calls skipped due to low confidence\n",
    "                        predictions.append(torch.tensor(-1,).unsqueeze(dim=0))\n",
    "                        spectrograms_db_scale_per_category[0].append(spectrogram[idx, 1])\n",
    "\n",
    "        if len(predictions) > 0:\n",
    "            predictions = torch.cat(predictions, dim=0)\n",
    "\n",
    "        # -1 is for usv calls skipped due to low confidence\n",
    "        for category_class in [i-1 for i in range(6)]:\n",
    "            if len(predictions) > 0:\n",
    "                num_calls = int(torch.sum(predictions == category_class).numpy())\n",
    "            else:\n",
    "                num_calls = 0\n",
    "            num_calls_per_category_csv.append(num_calls)\n",
    "            categories_csv.append(category_class + 1)\n",
    "            wav_files_csv.append(wav_file.split(\"/\")[-1])\n",
    "\n",
    "        # add an empty line between wav files, for easier readability\n",
    "        num_calls_per_category_csv.append(\"\")\n",
    "        categories_csv.append(\"\")\n",
    "        wav_files_csv.append(\"\")\n",
    "\n",
    "        if plot_images:\n",
    "            Path(\"results/images/\").mkdir(parents=True, exist_ok=True)\n",
    "            for category, spectrograms in enumerate(spectrograms_db_scale_per_category):\n",
    "                if len(spectrograms) > 0:\n",
    "                    # need to be of shape b,c,h,w -> add c=1\n",
    "                    spectrograms = torch.stack(spectrograms, dim=0).unsqueeze(dim=1)\n",
    "                    image = torchvision.utils.make_grid(spectrograms, normalize=True, scale_each=True)[0]\n",
    "                    plt.figure(figsize=(image.shape[0]/100, image.shape[1]/100), dpi=1000)\n",
    "                    plt.imshow(image)\n",
    "                    plt.axis('off')\n",
    "                    wav_file_name = os.path.normpath(wav_file).split(os.path.sep)[-1]\n",
    "                    plt.savefig(\"results/images/\" + wav_file_name + \"_\" + str(category) + \".jpg\", bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    #torchvision.utils.save_image(image, \"results/images/\" + wav_file.split(\"/\")[-1] + \"_\" + str(category) + \".jpg\")\n",
    "\n",
    "        # in case a crash occurs during evaluation\n",
    "        Path(\"results/\").mkdir(parents=True, exist_ok=True)\n",
    "        np.savetxt(\"results/results.csv\", [p for p in zip(wav_files_csv, categories_csv, num_calls_per_category_csv)], delimiter=\";\", fmt='%s')\n",
    "    Path(\"results/\").mkdir(parents=True, exist_ok=True)\n",
    "    np.savetxt(\"results/results.csv\", [p for p in zip(wav_files_csv, categories_csv, num_calls_per_category_csv)], delimiter=\";\", fmt='%s')\n",
    "\n",
    "\n",
    "# custom cnn\n",
    "\n",
    "\"\"\"\n",
    "run_evaluation(\n",
    "    data_folder_dir=DATA_DIR,\n",
    "    model_path=MODEL_PATH_CUSTOM_CNN,\n",
    "    model_class=classification_net_cnn_image_lightning,\n",
    "    confidence_threshold=0.4,\n",
    "    plot_images=True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# efficentnet b5\n",
    "run_evaluation(\n",
    "    data_folder_dir=DATA_DIR,\n",
    "    model_path=MODEL_PATH_EFFICENTNETB5,\n",
    "    model_class=classification_net_cnn_image_lightning_EfficentNetB5,\n",
    "    confidence_threshold=0.4,\n",
    "    normalize_smooth_spec_individually=True,\n",
    "    plot_images=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9baa06f-bdbf-42a7-91be-f24d33e526f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df85e60f-3cb4-44d2-bae7-2247e6a8e838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
